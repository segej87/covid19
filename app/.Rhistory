by = c('Country.Region', 'Province.State')) %>%
left_join(populations, by = c('Country.Region', 'Province.State')) %>%
replace_na(list(Population = 1)) %>%
mutate(normalized_date = as.numeric(difftime(load_date, First100Date, unit = 'days'))),
envir = .GlobalEnv
)
assign(
'map_data',
dat %>%
mutate(ind = apply(dat, MARGIN = 1, FUN = function(x) {paste(x[c('Latitude', 'Longitude')], collapse = '.')})) %>%
filter(!(Latitude == 0 & Longitude == 0),
!(is.na(Latitude) | is.na(Longitude))) %>%
st_as_sf(coords = c('Longitude', 'Latitude'), crs = st_crs(world_base)) %>%
mutate(CombinedLocation = ifelse(is.na(Admin2), as.character(Location), paste(Admin2, Location, sep = ', '))) %>%
group_by(ind, Country.Region, CombinedLocation)  %>%
mutate(Confirmed_rate = Confirmed - lag(Confirmed, default = 0),
Deaths_rate = Deaths - lag(Deaths, default = 0),
Recovered_rate = Recovered - lag(Recovered, default = 0),
Confirmed_accel = Confirmed_rate - lag(Confirmed_rate, default = 0),
Deaths_accel = Deaths_rate - lag(Deaths_rate, default = 0),
Recovered_accel = Recovered_rate - lag(Recovered_rate, default = 0)) %>%
# left_join(populations, by = c('Country.Region', 'Province.State')) %>%
# replace_na(list(Population = 1)) %>%
filter(load_date == max(load_date, na.rm = TRUE)) %>%
mutate(Location_name = ifelse(Location == 'None', as.character(Country.Region), as.character(Location))),
envir = .GlobalEnv
)
assign(
'country_populations',
read.csv('data/country_pops.csv', stringsAsFactors = FALSE) %>%
mutate(Province.State = ifelse(is.na(Province.State) | Province.State == 'None',
as.character(Country.Region),
as.character(Province.State))) %>%
mutate(Country.Region = factor(Country.Region),
Province.State = factor(Province.State)) %>%
rename(CountryPopulation = Population),
envir = .GlobalEnv
)
assign(
'state_populations',
read.csv('data/state_pops.csv', stringsAsFactors = FALSE) %>%
mutate(Province.State = ifelse(is.na(Province.State) | Province.State == 'None',
as.character(Country.Region),
as.character(Province.State))) %>%
mutate(Country.Region = factor(Country.Region),
Province.State = factor(Province.State)),
envir = .GlobalEnv
)
assign(
'state_prov_grouped',
dat_summ %>%
group_by(load_date, Country.Region, Province.State) %>%
summarise(Confirmed = sum(Confirmed, na.rm = TRUE),
Deaths = sum(Deaths, na.rm = TRUE),
Recovered = sum(Recovered, na.rm = TRUE)) %>%
group_by(Country.Region, Province.State) %>%
mutate(Confirmed_rate = Confirmed - lag(Confirmed, default = 0),
Deaths_rate = Deaths - lag(Deaths, default = 0),
Recovered_rate = Recovered - lag(Recovered, default = 0),
Confirmed_accel = Confirmed_rate - lag(Confirmed_rate, default = 0),
Deaths_accel = Deaths_rate - lag(Deaths_rate, default = 0),
Recovered_accel = Recovered_rate - lag(Recovered_rate, default = 0)) %>%
left_join(dat_summ %>%
group_by(load_date, Country.Region, Province.State) %>%
summarise(Confirmed = sum(Confirmed, na.rm = TRUE)) %>%
filter(Confirmed >= 100) %>%
group_by(Country.Region, Province.State) %>%
summarise(First100Date = min(load_date, na.rm = TRUE)),
by = c('Country.Region', 'Province.State')) %>%
left_join(populations, by = c('Country.Region', 'Province.State')) %>%
replace_na(list(Population = 1)) %>%
mutate(normalized_date = as.numeric(difftime(load_date, First100Date, unit = 'days'))),
envir = .GlobalEnv
)
assign(
'map_data',
dat %>%
mutate(ind = apply(dat, MARGIN = 1, FUN = function(x) {paste(x[c('Latitude', 'Longitude')], collapse = '.')})) %>%
filter(!(Latitude == 0 & Longitude == 0),
!(is.na(Latitude) | is.na(Longitude))) %>%
st_as_sf(coords = c('Longitude', 'Latitude'), crs = st_crs(world_base)) %>%
mutate(CombinedLocation = ifelse(is.na(Admin2), as.character(Location), paste(Admin2, Location, sep = ', '))) %>%
group_by(ind, Country.Region, CombinedLocation)  %>%
mutate(Confirmed_rate = Confirmed - lag(Confirmed, default = 0),
Deaths_rate = Deaths - lag(Deaths, default = 0),
Recovered_rate = Recovered - lag(Recovered, default = 0),
Confirmed_accel = Confirmed_rate - lag(Confirmed_rate, default = 0),
Deaths_accel = Deaths_rate - lag(Deaths_rate, default = 0),
Recovered_accel = Recovered_rate - lag(Recovered_rate, default = 0)) %>%
# left_join(populations, by = c('Country.Region', 'Province.State')) %>%
# replace_na(list(Population = 1)) %>%
filter(load_date == max(load_date, na.rm = TRUE)) %>%
mutate(Location_name = ifelse(Location == 'None', as.character(Country.Region), as.character(Location))),
envir = .GlobalEnv
)
head(map-data)
head(map_data)
map_data[which(map_data$Location == 'None'),]
shiny::runApp()
as.list(dat[,c('Country.Region', 'State.Province')])
as.list(dat[,c('Country.Region', 'Province.State')])
assign(
'state_prov_choices',
dat %>%
group_by(Country.Region) %>%
summarise(state_options = as.vector(Province.State))
)
assign(
'state_prov_choices',
dat %>%
group_by(Country.Region) %>%
summarise(state_options = paste(Province.State, collapse = ', '))
)
head(dat)
head(state_prov_choices)
assign(
'state_prov_choices',
dat %>%
group_by(Country.Region) %>%
summarise(state_options = paste(unique(Province.State), collapse = ', '))
)
head(state_prov_choices)
state_prov_choices
assign(
'state_prov_choices',
dat %>%
group_by(Country.Region) %>%
summarise(state_options = paste(unique(Province.State), collapse = ', ')) %>%
as.list
)
state_prov_choices
assign(
'state_prov_choices',
dat %>%
group_by(Country.Region) %>%
summarise(state_options = paste(unique(Province.State), collapse = ', ')) %>%
as.list(names = Country.Region)
)
state_prov_choices
names(state_prov_choices)
assign(
'state_prov_choices',
dat %>%
group_by(Country.Region) %>%
summarise(state_options = paste(unique(Province.State), collapse = ', '))
)
state_prov_choices
test <- as.list(state_prov_choices$state_options)
names(test) <- state_prov_choices$state_options
head(test)
test <- strsplit(test, ', ')
test <- strsplit(', ', test)
head(test)
?strsplit
test <- as.list(state_prov_choices$state_options)
names(test) <- state_prov_choices$state_options
state_prov_options <- dat %>%
group_by(Country.Region) %>%
summarise(state_options = paste(unique(Province.State), collapse = ';;; '))
state_prov_list <- as.list(state_prov_options$state_options)
names(state_prov_list) <- state_prov_options$Country.Region
head(state_prov_list)
test <- lapply(state_prov_list, FUN = function(x) strsplit(x, ';;; '))
head(test)
test <- sapply(state_prov_list, FUN = function(x) strsplit(x, ';;; '))
head(test)
test['US']
test['Antigua and Barbuda']
runApp()
countries = c('Afghanistan', 'Albania', 'Algeria')
state_prov_choices[countries]
state_prov_options
state_prov_choices
state_prov_list
# state_prov <- sort(unique(as.character((dat %>%
#                                           filter(Country.Region %in% input$countries))$Province.State)))
state_prov <- state_prov_list[input$countries]
state_prov_list[countries]
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
getwd()
runApp()
urlfile='https://api.github.com/repos/CSSEGISandData/COVID-19/git/trees/master?recursive=1'
req <- tryCatch({
GET(urlfile)
}, error = function(e) {
'override'
})
if (length(req) == 1) {
if (req == 'override') {
warning('Could not connect to server - loading most recent data')
files <- list.files('data', pattern = '.RData')
files_as_dates <- as.Date(gsub('.Rdata', '', files), format = '%m-%d-%Y')
assign('max_data_date', max(files_as_dates), envir = .GlobalEnv)
assign('connected', FALSE, envir = .GlobalEnv)
load(file.path('data', files[which(files_as_dates == max(files_as_dates))]))
return(dat)
}
}
stop_for_status(req)
urlfile
req
stop_for_status(req)
runApp()
shiny::runApp()
library(httr)
library(progress)
library(curl)
urlfile='https://api.github.com/repos/CSSEGISandData/COVID-19/git/trees/master?recursive=1'
req <- tryCatch({
GET(urlfile)
}, error = function(e) {
'override'
})
req$status_code == 403
warning(req$content, paste('- loading most recent data'))
warning(req$message, paste('- loading most recent data'))
rawToChar(req$content)
warning(fromJSON(rawToChar(req$message)), paste('- loading most recent data'))
warning(fromJSON(rawToChar(req$content)), paste('- loading most recent data'))
warning(paste(fromJSON(rawToChar(req$content)), '- loading most recent data'))
warning(paste('Loading most recent data - ', fromJSON(rawToChar(req$content))))
?GET
library(httr)
library(progress)
library(curl)
urlfile='https://api.github.com/repos/CSSEGISandData/COVID-19/git/trees/master?recursive=1'
token <- 'd6b6ff7b7882232fa6125208d9202973880c395f'
req <- tryCatch({
GET(urlfile, sign_oauth2.0(token))
}, error = function(e) {
'override'
})
req
GET(urlfile, sign_oauth2.0(token))
GET(urlfile, config(sign_oauth2.0 = token))
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
file.edit('~/.Renviron')
Sys.getenv('GITHUB_TOKEN')
file.edit('~/.Renviron')
Sys.getenv('GITHUB_TOKEN')
github_token <- function() {
token <- Sys.getenv('GITHUB_TOKEN')
if (identical(token, '')) {
warning('No oAuth token found, going unauthenticated')
}
return(token)
}
req <- tryCatch({
token <- github_token
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
}, warning = function(w) {
GET(urlfile)
}, error = function(e) {
'override'
})
req
token <- github_token
token
token <- github_token()
token
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
shiny::runApp()
library(httr)
library(progress)
library(curl)
urlfile='https://api.github.com/repos/CSSEGISandData/COVID-19/git/trees/master?recursive=1'
github_token <- function() {
token <- Sys.getenv('GITHUB_TOKEN')
if (identical(token, '')) {
warning('No oAuth token found, going unauthenticated')
}
return(token)
}
load_data <- function() {
req <- tryCatch({
token <- github_token()
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
}, warning = function(w) {
cat(w)
GET(urlfile)
}, error = function(e) {
'override'
})
if (length(req) == 1) {
if (req == 'override') {
warning('Could not connect to server - loading most recent data')
files <- list.files('data', pattern = '.RData')
files_as_dates <- as.Date(gsub('.Rdata', '', files), format = '%m-%d-%Y')
assign('max_data_date', max(files_as_dates), envir = .GlobalEnv)
assign('connected', FALSE, envir = .GlobalEnv)
load(file.path('data', files[which(files_as_dates == max(files_as_dates))]))
return(dat)
}
} else if (req$status_code == 403) {
warning(paste('Loading most recent data - ', fromJSON(rawToChar(req$content))))
files <- list.files('data', pattern = '.RData')
files_as_dates <- as.Date(gsub('.Rdata', '', files), format = '%m-%d-%Y')
assign('max_data_date', max(files_as_dates), envir = .GlobalEnv)
assign('connected', FALSE, envir = .GlobalEnv)
load(file.path('data', files[which(files_as_dates == max(files_as_dates))]))
return(dat)
}
stop_for_status(req)
filelist <- unlist(lapply(content(req)$tree, "[", "path"), use.names = F)
# Get the path with daily reports
get_path_level <- function(x, ind) {
unlist(strsplit(paths_with_daily, split = '/'))[ind]
}
paths_with_daily <- grep('daily_reports', filelist, value = TRUE)
root_dir <- unique(sapply(paths_with_daily, FUN = get_path_level, ind = 1))
next_level <- unique(sapply(paths_with_daily, FUN = get_path_level, ind = 2))
# Get all data file names
data_files <- filelist[which(grepl(file.path(root_dir, next_level), filelist) &
!grepl('README|[.]gitignore', filelist) &
grepl('[.]csv', filelist))]
dates <- as.Date(gsub(paste0(file.path(root_dir, next_level), '|[/]|([.]csv)'), '', data_files), format = '%m-%d-%Y')
max_date <- max(dates)
assign('max_data_date', max_date, envir = .GlobalEnv)
assign('connected', TRUE, envir = .GlobalEnv)
# Col specification sets
col_specs <- list(
Set_1 = cols(
FIPS = col_integer(),
Admin2 = col_character(),
`Province/State` = col_character(),
`Country/Region` = col_character(),
`Last Update` = col_datetime(format = ""),
Confirmed = col_double(),
Deaths = col_double(),
Recovered = col_double(),
Active = col_double(),
Latitude = col_double(),
Longitude = col_double(),
Combined_Key = col_character()
),
Set_2 = cols(
FIPS = col_integer(),
Admin2 = col_character(),
Province_State = col_character(),
Country_Region = col_character(),
Last_Update = col_datetime(format = ""),
Confirmed = col_double(),
Deaths = col_double(),
Recovered = col_double(),
Active = col_double(),
Lat = col_double(),
Long_ = col_double(),
Combined_Key = col_character()
)
)
col_names <- names(col_specs$cols)
path <- 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/'
data_file <- file.path('data', sprintf('%s.RData', strftime(max_date, '%m-%d-%Y')))
if (file.exists(data_file)) {
cat('Loading file\n')
load(data_file)
return(dat)
} else {
cat('Newer data detected - downloading')
dat <- c()
pb <- progress_bar$new(total = length(data_files))
for (d in data_files) {
csv_data <- tryCatch({
readr::read_csv(url(file.path(path, d)), col_types = col_specs[[1]], progress = TRUE)
}, warning = function(w) {
if (grepl('don\'t match the column names', w)) {
tryCatch({
readr::read_csv(url(file.path(path, d)), col_types = col_specs[[2]], progress = TRUE)
})
}
}) %>%
rename_all(gsub, pattern = 'Lat$', replacement = 'Latitude') %>%
rename_all(gsub, pattern = 'Long[_.]$', replacement = 'Longitude') %>%
rename_all(gsub, pattern = "[^[:alnum:]]", replacement = '.')
if (length(class(csv_data$Last.Update)) == 1) {
if (class(csv_data$Last.Update) == 'character') {
tryCatch({
csv_data <- csv_data %>% mutate(Last.Update = as.POSIXct(Last.Update, format = '%m/%d/%Y %H:%M'))
})
}
}
date = as.Date(basename(gsub('[.][[:alnum:]]+$', '', d)), '%m-%d-%Y')
dat <- dat %>%
bind_rows(csv_data %>%
mutate(load_date = date))
pb$tick()
}
dat$Country.Region <- sapply(dat$Country.Region, FUN = function(x) {ifelse(grepl('China', x), 'China', x)})
dat <- dat %>%
replace_na(list(Province.State = Country.Region, Country.Region = 'Unknown Country')) %>%
mutate_if(is.character, as.factor)
if (!dir.exists('data')) dir.create('data')
save(dat, file = file.path('data', sprintf('%s.RData', strftime(max_date, '%m-%d-%Y'))))
return(dat)
}
}
req <- tryCatch({
token <- github_token()
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
}, warning = function(w) {
cat(w)
GET(urlfile)
}, error = function(e) {
'override'
})
req
file.edit('~/.renviron')
library(httr)
library(progress)
library(curl)
urlfile='https://api.github.com/repos/CSSEGISandData/COVID-19/git/trees/master?recursive=1'
github_token <- function() {
token <- Sys.getenv('GITHUB_TOKEN')
if (identical(token, '')) {
warning('No oAuth token found, going unauthenticated')
}
return(token)
}
req <- tryCatch({
token <- github_token()
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
}, warning = function(w) {
cat(w)
GET(urlfile)
}, error = function(e) {
cat(e)
'override'
})
token <- github_token()
cat(w)
token <- github_token()
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
GET(urlfile)
req <- tryCatch({
token <- github_token()
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
}, warning = function(w) {
cat(w)
GET(urlfile)
}, error = function(e) {
cat(e)
'override'
})
assign('e', e, envir = .GlobalEnv)
req <- tryCatch({
token <- github_token()
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
}, warning = function(w) {
cat(w)
GET(urlfile)
}, error = function(e) {
assign('e', e, envir = .GlobalEnv)
cat(e)
'override'
})
e
assign('w', w, envir = .GlobalEnv)
req <- tryCatch({
token <- github_token()
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
}, warning = function(w) {
assign('w', w, envir = .GlobalEnv)
cat(w)
GET(urlfile)
}, error = function(e) {
assign('e', e, envir = .GlobalEnv)
cat(e)
'override'
})
w
w$message
req <- tryCatch({
token <- github_token()
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
}, warning = function(w) {
assign('w', w, envir = .GlobalEnv)
GET(urlfile)
}, error = function(e) {
cat(e$message)
'override'
})
w
req <- tryCatch({
token <- github_token()
GET(urlfile, add_headers(Authorization = paste('Bearer', token, sep = ' ')))
}, warning = function(w) {
cat(w$message)
GET(urlfile)
}, error = function(e) {
cat(e$message)
'override'
})
